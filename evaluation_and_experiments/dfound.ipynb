{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51047331-b64e-44ce-bb43-e2de07bd5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "embed_dir = Path('/Users/mma0448/tmp/embeds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e7fb0f-f75c-428b-b8bf-301c945677ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 16:02:43.018983: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import from_pretrained_keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c992f44-9425-4c3b-a354-6cb23745350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate user for HuggingFace if needed. Enter token below if requested.\n",
    "from huggingface_hub.utils import HfFolder\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "if HfFolder.get_token() is None:\n",
    "    from huggingface_hub import notebook_login\n",
    "    notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bb9d9a1-dfc3-4029-baee-ee04e7082773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86db7bf7cad4134b9a1b9529d132874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = from_pretrained_keras(\"google/derm-foundation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a538aee0-a46d-472e-b78c-1c14268e5f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import Image as IPImage, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "052f6463-12ee-443e-8a7d-47ebf66f072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5798304f-35af-4ddb-86d2-c2e828e0a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path('/Users/mma0448/tmp/image_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cb9bd7d-ebb2-431c-8015-5ce4936063d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageForDFDataset(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        metadata_path: Path, \n",
    "        transform=None, \n",
    "    ):\n",
    "        self.data_list = pd.read_csv(metadata_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(\n",
    "        self, \n",
    "        idx: int,\n",
    "    ):\n",
    "        row = self.data_list.iloc[idx]\n",
    "        img_path, label = row['filename'], row['label']\n",
    "\n",
    "        # keep either Albumentations or torchvision happy\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return {\n",
    "            'image': img, \n",
    "            'label': label,\n",
    "            'filename': str(img_path)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "772583f4-8a6c-4ff9-86d2-a59fb07238f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose\n",
    "\n",
    "class ConvertToMakeModelHappy(object):\n",
    "    def __init__(self, format='PNG'):\n",
    "        self.format = format\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        buf = BytesIO()\n",
    "        sample.convert('RGB').save(buf, self.format)\n",
    "        image_bytes = buf.getvalue()\n",
    "        # return image_bytes\n",
    "        input_tensor= tf.train.Example(features=tf.train.Features(\n",
    "            feature={\n",
    "                'image/encoded': tf.train.Feature(\n",
    "                    bytes_list=tf.train.BytesList(value=[image_bytes]))\n",
    "            })\n",
    "        ).SerializeToString()\n",
    "        return input_tensor        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cd66888-2d0b-4d58-a1e7-64cb33f6fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = ConvertToMakeModelHappy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb0668e8-b1f7-49d8-b9ca-d309761bfb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dataset and loader\n",
    "train_set = ImageForDFDataset(\n",
    "    data_root / 'train.csv', \n",
    "    transform=transforms\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03eccc0e-dc9c-4151-bceb-1928397ee1fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 706/706 [10:17:12<00:00, 52.45s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9841"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "infer = loaded_model.signatures[\"serving_default\"]\n",
    "\n",
    "df = pd.DataFrame(columns=['feature_path', 'label'])\n",
    "counter = 0\n",
    "for batch in tqdm(train_loader):\n",
    "    for img, label in zip(batch['image'], batch['label']):\n",
    "        counter += 1\n",
    "        \n",
    "        save_path = embed_dir / f'{counter:06d}.npy'\n",
    "        if save_path.exists():\n",
    "            continue\n",
    "        \n",
    "        output = infer(inputs=tf.constant([img]))\n",
    "        \n",
    "        # Extract the embedding vector\n",
    "        embedding_vector = output['embedding'].numpy().flatten()\n",
    "        \n",
    "        np.save(save_path, embedding_vector)\n",
    "        df.loc[counter, 'feature_path'] = save_path\n",
    "        df.loc[counter, 'label'] = label\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cb03f32-a336-4e76-9de5-7b8fc52fe629",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_dir = Path('/Users/mma0448/tmp/dfound_md')\n",
    "md_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70f35598-bfae-40ad-91ea-9f1889f3d1f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(md_dir / 'train_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ebb1905-8eb9-4bcb-8499-ff91cc156a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dataset and loader\n",
    "test_set = ImageForDFDataset(\n",
    "    data_root / 'test.csv', \n",
    "    transform=transforms\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a960b858-863f-4856-a190-539a9f1ac0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dir = Path('/Users/mma0448/tmp/test_embeds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ae092e8-d084-4921-8d33-2debe6577213",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87e67a00-7266-47d8-b13d-3120bd29bc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 125/125 [2:16:14<00:00, 65.39s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer = loaded_model.signatures[\"serving_default\"]\n",
    "\n",
    "df = pd.DataFrame(columns=['feature_path', 'label'])\n",
    "counter = 0\n",
    "for batch in tqdm(test_loader):\n",
    "    for img, label in zip(batch['image'], batch['label']):\n",
    "        counter += 1\n",
    "        \n",
    "        save_path = embed_dir / f'test_{counter:06d}.npy'\n",
    "        if save_path.exists():\n",
    "            continue\n",
    "        \n",
    "        output = infer(inputs=tf.constant([img]))\n",
    "        \n",
    "        # Extract the embedding vector\n",
    "        embedding_vector = output['embedding'].numpy().flatten()\n",
    "        \n",
    "        np.save(save_path, embedding_vector)\n",
    "        df.loc[counter, 'feature_path'] = save_path\n",
    "        df.loc[counter, 'label'] = label\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acaef4ef-7ea3-46ab-87b5-66094089474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(md_dir / 'test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
